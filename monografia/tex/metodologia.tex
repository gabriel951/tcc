Neste capítulo, descreve-se a metodologia usada em toda a pesquisa. 
% minha escrita
Detalha-se como foi feito o levantamento
do estado da arte, a obtenção e utilização dos dados, a seleção de
atributos, a eliminação de atributos devido à \textit{missing values}, a eliminação
de \textit{outliers}, a análise preliminar por meio de estatística descritiva, a
eliminação de atributos relacionados ou irrelevantes, as divisões em treino e teste e
as divisões em semestre, a escolha dos algoritmos de aprendizagem de máquina, e a forma
de avaliar o desempenho destes.  
\par Faz-se nesse parágrafo um breve comentário acerca da metodologia usada. A
metodologia de mineração de dados usada é baseada no modelo CRISP-DM. Foram
utilizados dados reais descaracterizados de alunos da UnB e de seus desempenhos. Para
induzir os modelos e avaliar o desempenho deles, os dados foram divididos em dados de
treino, validação e teste, segundo a abordagem \textit{holdout}. Os dados dos cursos
analisados foram agrupados nos grupos: licenciatura, FT e computação. Os modelos
preditos foram induzidos com os algoritmos Naive Bayes, Random Forest, ANN, regressor
linear e SVR, disponibilizados pela biblioteca \texttt{scikit-learn} (v. 0.18.1) da linguagem
Python. A performance dos modelos foi mensurada com a métrica \textit{F-measure}, e
comparada à obtida com o classificador ZeroR. 


\section{Levantamento do Estado da Arte}
Foi feito o levantamento do estado da arte através da leitura de diversos artigos.
Procurou-se assim compreender
quais fatores são importantes para a evasão \cite{adeodato}
\cite{hoed_fatores} \cite{dropout_finland}, como técnicas de
aprendizagem de máquina podem ser utilizadas para resolver o problema \cite{adeodato}
 \cite{data_mining_retention} 
e como trabalhar especificamente com os dados da UnB \cite{manual_calouro} 
\cite{hoed_sobrevivencia}. 

\section{Obtenção e Utilização dos Dados}
Obtiveram-se informações descaracterizadas relativas aos dados sociais e ao
desempenho acadêmico de alunos de graduação da UnB obtidos do \acrshort{SIGRA} -
Sistema de Informação da Graduação. Todos os dados utilizados vieram
de uma só fonte, de modo que o comum problema encontrado na área de mineração de
dados de garantir a consistência dos dados entre várias fontes não foi enfrentado. 
\par Optou-se por restringir a pesquisa apenas aos alunos que entraram a partir de
2000 e saíram até 2016, de modo a trabalhar com dados mais recentes. 
Para simplificar a análise, decidiu-se trabalhar apenas com uma área
específica (computação), de modo que apenas os seguintes cursos foram considerados: 
\begin{itemize}
    \item Ciência da Computação (Bacharelado)
    \item Computação (Licenciatura)
    \item Engenharia da Computação 
    \item Engenharia de Redes
    \item Engenharia de Software
    \item Engenharia Mecatrônica
\end{itemize}

\section{Seleção Preliminar de Atributos}
Com base no levantamento do estado da arte feito, selecionou-se quais atributos
teriam melhor condição de serem significativos para que um aluno fosse ou não
desligado. Assim sendo, lista-se a seguir os atributos sociais considerados em uma análise
inicial:
\begin{itemize}
        \item Cotista (ou não)
        \item Curso
        \item Forma de Ingresso
        \item Idade
        \item Raça
        \item Sexo
        \item Tipo da Escola 
\end{itemize}

Além de dados sociais, utilizaram-se os seguintes atributos (relativos ao desempenho
acadêmico): 
\begin{itemize}
    \item Coeficiente de Melhora Acadêmica
    \item Indicador de Aluno em Condição
    \item Média do Período
    \item Posição em relação ao semestre que ingressou
    \item Quantidade de créditos já integralizados
    \item Taxa de Aprovação, Taxa de Reprovação e Taxa de Trancamento
    \item Taxa de aprovação na disciplina mais difícil de cada semestre
\end{itemize}

\par O coeficiente de melhora acadêmica é definido como sendo a razão entre o IRA do
aluno em um semestre pelo IRA do aluno no semestre anterior. Dessa maneira, o
coeficiente de melhora acadêmica mostra se o desempenho do aluno está
melhorando, piorando ou se encontra estável.  
\par A média do período é calculada da mesma forma que o IRA, mas considerando apenas
as menções obtidas em um determinado semestre. Assim como o IRA, a média do período
varia entre 0 e 5.
\par A posição em relação ao semestre $P$ para um determinado aluno é definida como sendo:
o número de alunos com IRA maior que o do estudante em questão
(considerando apenas aqueles que entraram no mesmo curso do estudante, no mesmo ano e
no mesmo semestre). Assim, um aluno com posição $P = 0$ é aquele que tem o maior
IRA em relação a seus colegas que entraram no mesmo curso durante o mesmo ano e
semestre.  
\par Como todos os cursos da UnB requerem uma quantidade de créditos mínima para
graduação, incluiu-se o atributos quantidade de créditos já integralizados. 
\par A taxa de aprovação é definida como a razão entre o número de matérias cursadas
pelo aluno com aprovação pelo número de matérias cursadas pelo aluno. Analogamente, a
taxa de reprovação é definida como a razão entre o número de matérias cursadas pelo
aluno com reprovação pelo número de matérias cursadas pelo aluno. Deve-se dizer que 
incluir a taxa de aprovação e a de reprovação não é, a priori, redundante, já que
além de ser aprovado ou reprovado em uma matéria, outra possibilidade é o aluno
realizar o trancamento.  Pensando nisso, definiu-se a taxa de trancamento como sendo
a razão entre o número de matérias trancadas pelo aluno pelo número de matérias
cursadas pelo aluno.
\par Por fim, a taxa de aprovação na disciplina mais difícil do semestre é definida
como sendo a razão entre o número de aprovações na disciplina mais difícil do
semestre pelo número de semestres na UnB. A disciplina considerada como a mais
difícil do semestre é aquela com a maior taxa de reprovação. 
\par Deve-se destacar que, para um mesmo aluno, os atributos relacionados ao
desempenho variam conforme o semestre considerado. O mesmo não ocorre para os
atributos sociais. 

\section{Eliminação de Atributos Devido a Missing Values}
Optou-se por eliminar atributos cuja quantidade de entradas com \textit{missing
values} fosse superior à 40\%. Assim, eliminaram-se os atributos raça e tipo da
escola. Os gráficos de barra para tais atributos se encontram no Apêndice
\ref{graf_miss_value}.

\section{Eliminação de Outliers}
Decidiu-se não trabalhar com casos de alunos que após ingressar na universidade não
demonstraram interesse em cursar matérias (por exemplo, aqueles que reprovaram em
todas as disciplinas com SR). Tais casos foram tratados como \textit{outliers}.
Após a análise individual de cada caso, os \textit{outliers} foram eliminados do espaço
amostral. Eliminaram-se 233 estudantes do espaço amostral dessa maneira, ficando-se
assim com 4536 estudantes.

\section{Estatística Descritiva}
Foi feita uma análise preliminar por meio de estatística descritiva. As subseções
seguintes explicam cada um dos procedimentos adotados: a mudança na base
de dados realizada, a mudança nos valores de alguns atributos e os gráficos de barra
e histogramas finais. 

\subsection{Mudança na Base de Dados}
\par Foi possível observar que os atributos variavam significativamente de acordo com
o curso. Isso se deve ao fato de cada curso ter currículo diferente dos
demais, alguns cursos serem de instituições diferentes (Faculdade de Tecnlogia
(\acrshort{FT}) ou Instituto de Ciências Exatas (\acrshort{IE}), por exemplo) e os
cursos possuírem ``maturidade'' diferentes (devido à data início de cada curso ser
diferente). Outra observação preliminar possível foi a de que a proporção de alunos
que ingressam com idade avançada que se forma é menor do que a de alunos mais jovens.
Após a aplicação da técnica de tabela de contingência, 
essas observações levaram a partição da base de dados original em quatro bases de dados: 

\begin{itemize}
    \item Alunos Jovens da FT: contém todos os alunos que ingressaram com 30
        anos ou menos que cursam Engenharia de Redes ou Engenharia Mecatrônica. Tais
        cursos tem a peculiaridade de estarem associados à FT, 
        diferentemente de todos os demais.  
    \item Alunos Jovens de Licenciatura: contém todos os alunos que ingressaram com
        30 anos ou menos que cursam Computação (Licenciatura). O curso de
        Licenciatura tem a peculiaridade de ser o único noturno. 
    \item Alunos Jovens de Computação: contém todos os alunos que ingressaram com 30
        anos ou menos que cursam Ciência da Computação, Engenharia da Computação ou
        Engenharia de Software. 
    \item Alunos Seniores: contém todos os alunos com mais de 30 anos.
\end{itemize}
Devido à baixa quantidade de alunos seniores, não se separou tal categoria em grupos.
A evidência fornecida pela estatística descritiva para essa separação
encontra-se na Seção \ref{justificativa_4_base_dados}.

\subsection{Mudança nos Valores de Atributos}
\par Dois atributos tiveram alguns de seus valores agrupados em categorias para
facilitar o posterior tratamento dos dados. Tais atributos são a forma de entrada e a
forma de saída. A distribuição original de tais atributos pode ser vista na Seção 
\ref{just_mud_atr}. 
\par No atributo forma de entrada, de modo a eliminar os vários valores com poucas
instâncias na base de dados, criou-se a categoria ``outros''. Assim, apenas três 
categorias foram consideradas: vestibular, PAS e outros. 
\par Decidiu-se trabalhar com apenas três valores de forma de saída: graduou, evadiu
e migrou. Essa última categoria foi criada para agrupar os casos de transferência,
mudança de curso, mudança de turno e realização de um novo vestibular. 

\subsection{Gráficos de Barra e Histogramas}
Após as modificações descritas nas subseções anteriores, fez-se o gráfico de barra
para os atributos discretos e os histogramas para os atributos contínuos.
Considerou-se, para isso, a divisão dos dados nas quatro bases de dados descritas. Tais
resultados encontram-se na Seção \ref{graf_bar_hist}.

\section{Eliminação de Atributos Relacionados ou Irrelevantes}
\par Na área de aprendizagem de máquina, uma etapa fundamental é a da seleção de
atributos \cite{useful_ml}, onde deve-se realizar a
eliminação de atributos que estejam muito relacionados entre si e também a eliminação
de atributos irrelevantes. 
 
\par Avaliou-se o grau de relacionamento entre os diversos atributos por meio do
coeficiente de correlação de Kendall. Optou-se por eliminar uma variável de cada par
que apresentasse mais de 80\% de correlação. Os atributos taxa de aprovação e taxa de
reprovação apresentaram, para todas as bases de dados, alto relacionamento. Assim
sendo, eliminou-se o atributo taxa de reprovação de análises posteriores. 

\par Para descobrir os atributos irrelevantes, dentro daqueles originalmente
pensados, utilizaram-se árvores de decisão: os atributos que não apareceram nas
árvores de decisão foram eliminados das fases posteriores. Esse procedimento foi
feito para cada uma das quatro bases de dados. Para os alunos jovens da licenciatura,
obteve-se que o atributo curso não era relevante (o que era esperado já que todos os alunos
desse grupo tem o mesmo curso). Para os alunos seniores, obteve-se que os atributos
curso, cota e taxa de trancamento são irrelevantes. Para as outras bases de dados, nenhum
atributo foi classificado como irrelevante. 

\section{Divisão em Treino e Teste}
Como tradicionalmente ocorre no domínio de análise preditiva, houve a separação dos
dados entre dados de treino e dados de teste. Os dados abrangiam alunos que entraram
no período de 2000 até 2016 e já saíram da universidade. Aqueles alunos que entraram
antes de 2010 formaram o conjunto dos dados de treino, enquanto que os alunos que
entraram de 2010 em diante formaram o conjunto dos dados de teste. 

% não quis incluir. Se incluir e quiser fazer bem feito, explicar pq não se corrigiu
% tal desproporção
%\par Constatou-se uma grande diferença na proporção de alunos que se formava quando se
%comparava os dados de treino e os dados de teste. De fato, 53\% dos
%alunos dos dados de treino se mostraram capaz de conclui o curso, enquanto que para
%os dados de teste, a percentagem foi de 18\%. 
%\par Para entender a explicação para esse fenômeno, considere, por exemplo, os alunos
%ingressantes na UnB no ano de 2014. Aqueles que irão se graduar, não o farão até 2016
%e, portanto, não aparecerão em nossa amostra. Por outro lado, alguns dos que irão
%evadir o farão até 2016, aparecendo assim em nossa amostra. Essa é a explicação para
%o desbalanceamento da proporção de alunos que graduaram nos dados de teste. 

\section{A Divisão em Semestres}
Para o problema de negócio considerado na pesquisa, é necessário que o sistema
previsor seja capaz de calcular o risco de alunos evadirem tanto para estudantes nos
semestres iniciais do curso quanto para estudantes mais adiantados. Relacionado a
isso, tem-se que alguns atributos dos alunos, como por exemplo a taxa de aprovação,
mudam a cada semestre. Tal fato deve ser considerado na hora de treinar os modelos. 
\par Pensando nisso, os modelos de mineração de dados são induzidos
separadamente para cada semestre. Assim, inicialmente os modelos são induzidos com os
dados relativos ao 1º semestre de cada aluno do conjunto de treino e são
testados com os dados relativos ao 1º semestre de cada aluno do conjunto de
teste. Após isso, repete-se tal procedimento para os dados dos alunos relativos ao
2º semestre e assim sucessivamente. 
\par Caso esteja-se estudando um semestre para o
qual o aluno em questão já saiu da UnB (por exemplo, está se estudando a capacidade
do sistema previsor para alunos no 10º semestre e o aluno em questão saiu da UnB ao
fim do 8º semestre) tal aluno não entra no conjunto de treino/teste para o semestre
considerado.   

\section{Algoritmos de Aprendizagem de Máquina Estudados e Retroalimentação} 
As técnicas de aprendizagem de máquina utilizadas para a predição de alunos em risco
de evasão foram: \textit{Naive Bayes}, \textit{random forests}, rede neural, regressor linear e
SVR. Utilizou-se a biblioteca \texttt{scikit-learn} (versão 0.18.1) \cite{sklearn}, da
linguagem de programação Python.
\par Para cada um desses algoritmos, estudou-se se
utilizar retroalimentação poderia melhorar o desempenho. A retroalimentação
funcionaria da seguinte forma: o modelo de aprendizagem de máquina, na hora de tentar
prever o desempenho para um semestre $x$, receberia as chances do aluno
graduar/evadir/migrar calculada por esse mesmo modelo para o semestre $x-1$.
Para cada modelo estudado, analisou-se seu desempenho com e sem
retroalimentação. 

\section{Ajuste de Parâmetros}
Estimou-se quais seriam os melhores parâmetros para os seguintes algoritmos de
aprendizagem de máquina: \textit{Naive Bayes}, rede neural e SVR. Para os demais,
seguiu-se as configurações padrão da biblioteca \texttt{scikit-learn}.  
Para isso, utilizou-se validação, como descrito a seguir. Inicialmente, dividiu-se o
conjunto que não era de teste (consistindo dos alunos que entraram antes de 2010) em
dois subconjuntos: o conjunto de treino (alunos que entraram antes de 2007) e o
conjunto de validação (alunos que entraram de 2007 em diante). Depois, cada
configuração de parâmetros de cada método treinava no conjunto de treino e tinha seu
desempenho avaliado no conjunto de validação. 
\par Por fim, para escolher a melhor configuração de cada modelo de aprendizagem de
máquina, considerou-se, para cada configuração, o desempenho obtido semestre a
semestre.  Assumindo uma distribuição normal,
obtinha-se o intervalo de confiança do desempenho do modelo sob à configuração sendo
testada.  Para cada modelo, escolhia-se a configuração com menor intervalo de
confiança, desde que tal intervalo tivesse intersecção não vazia com o intervalo de
confiança da configuração com melhor desempenho. Adotou-se um intervalo de confiança
de 95\%.  As configurações obtidas para cada modelo são mostradas na Seção
\ref{conf_ml_models}.

\subsection{Ajuste de Parâmetros Para Redes Neurais}
Estimou-se primeiramente a quantidade de neurônios para a camada oculta, testando o
desempenho das \acrshort{ANN}s com 12, 24, 36 e 100 neurônios.
Em seguida, testou-se a taxa de aprendizagem para a rede neural, experimentando os
valores 0.001 (padrão da biblioteca), 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9 e
1.0. Os resultados são mostrados na Seção \ref{ann_best_conf}.

\subsection{Ajuste de Parâmetros Para SVR}
Estimou-se primeiramente a melhor configuração para o tipo de \textit{kernel} da
\acrshort{SVR}. Os tipos de \textit{kernel} analisados foram linear, polinomial e RBF. Em
seguida, variou-se o parâmetro de penalização $C$ da SVR, analisando-se o desempenho da
SVR quando $C$ era 0,5 1 e 2. Os resultados são mostrados na Seção
\ref{svr_best_conf}. 

\subsection{Estimativa de Parâmetros Para Naive Bayes}
O único parâmetro estimado para a técnica de aprendizagem de máquina \textit{Naive Bayes} foi
o tipo de distribuição que os atributos seguiam. Testou-se o desempenho de tal modelo
de aprendizagem de máquina assumindo-se que os atributos tinham as seguintes
distribuições: gaussiana, multinomial e Bernoulli. Os resultados são mostrados na
Seção \ref{nb_best_conf}. 

\section{Avaliação de Desempenho}
Após selecionar as melhores configurações para cada algoritmo de aprendizagem de
máquina, avaliou-se o desempenho de cada um dos modelos induzidos. Para isso, cada
modelo foi induzido no conjunto de treino (composto por alunos
que ingressaram antes de 2010) e teve seu desempenho avaliado no conjunto de teste
(composto por alunos que ingressaram de 2010 em diante). Esse processo foi feito para
cada um dos semestres estudados e funciona como explicado a seguir. 
\par Cada modelo induzido pelo conjunto de treino de cada base de dados gera, para
cada aluno em cada semestre ativo, uma tripla que indica a possibilidade do aluno
concluir, evadir ou migrar. O
maior valor da tripla é usado como sendo a previsão do modelo. Tal previsão é
então comparada com o que realmente aconteceu ao aluno. Se a previsão condiz com o
real, o modelo acerta; caso contrário, o modelo erra. 
\par A métrica utilizada para avaliar o desempenho dos
modelos foi a \textit{F-measure}. Um determinado modelo tem, para uma determinada
base de dados, vários valores de \textit{F-measure} calculados, um para cada semestre. Feito
isso, para sumarizar o desempenho do modelo para os alunos de teste de uma base de
dados, toma-se a média das \textit{F-measures} de cada semestre. Compararam-se os
resultados dos modelos entre si, e também com o modelo ZeroR. Os resultados
encontram-se na Seção \ref{results_ml_models}.

