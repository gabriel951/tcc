% todo: naive bayes should be in italic?
% todo: falar do ZeroR

Nesta capítulo, mostram-se as melhores configurações para os modelos de aprendizagem
de máquina estudados. Em seguida, apresentam-se os resultados obtidos para as
diversas técnicas de aprendizagem de máquina consideradas. Por fim, analisam-se os
resultados obtidos. 

\section{Configurações Obtidas Para Modelos de Aprendizagem de Máquina}
\label{conf_ml_models}
Nesta seção, analisa-se quais foram as melhores configurações obtidas para os
seguintes modelos de aprendizagem de máquina: ANN, SVR e Naive Bayes. 

\subsection{Configurações da ANN}
Inicialmente, estudou-se qual seria a quantidade ótima de neurônios da rede neural.
Depois, estudou-se qual seria o melhor valor para o parâmetro taxa de aprendizagem. 
Os resultados estão disponíveis na Tabela \ref{conf_ann}. 

\begin{table}
\begin{center}
\begin{tabular}[c]{| c | c | c |}
    \hline
    \textbf{Base de Dados} & \textbf{Número de Neurônios} & \textbf{Taxa de
    Aprendizagem} \\
    \hline
    Alunos Jovens da FT & 100 & 0.001 \\
    \hline
    Alunos Jovens da Licenciatura & 36 & 1.0 \\
    \hline
    Alunos Jovens da Computação & 36 & 0.001 \\
    \hline
    Alunos Seniores & 24  & 0.7 \\
    \hline
\end{tabular}
\end{center}
\caption{Melhor Escolha de Parâmetros Para ANN Conforme a Base de Dados}
\label{conf_ann}
\end{table}

Os resultados evidenciam que a melhor configuração, tanto para o número de neurônios
quanto para a taxa de aprendizagem, varia conforme a base de dados em questão. 

\subsection{Configurações da SVR}
Estudou-se como o tipo de \textit{kernel} e o parâmetro de penalização
poderiam ser escolhidos de modo a obter uma boa configuração para a SVR. Os
resultados são apresentados na Tabela \ref{svr_conf}. 

\begin{table}
\begin{center}
\begin{tabular}[c]{| c | c | c |}
    \hline
    \textbf{Base de Dados} & \textbf{Tipo de Kernel} & \textbf{Penalização} \\
    \hline
    Alunos Jovens da FT & linear & 1.0 \\
    \hline
    Alunos Jovens da Licenciatura & linear & 1.0 \\
    \hline
    Alunos Jovens da Computação & rbf & 1.0 \\
    \hline
    Alunos Seniores & linear & 1.0 \\
    \hline
\end{tabular}
\end{center}
\caption{Melhor Escolha de Parâmetros Para SVR Conforme a Base de Dados}
\label{svr_conf}
\end{table}

Os resultados mostram que as melhores configurações não dependem muito da base de
dados com a qual estamos trabalhando. Em três das quatro bases de dados, o tipo de
\textit{kernel} escolhido foi o linear. Em todas as bases de dados o valor para o
parâmetro de penalização foi $C = 1.0$.   

\subsection{Configuração do Naive Bayes}
Estudou-se como o tipo de distribuição assumida por cada atributo influenciou o
desempenho no modelo Naive Bayes. Os resultados são mostrados na Tabela \ref{conf_nb} e
evidenciam que a melhor escolha para o tipo de distribuição é bastante dependente da
base de dados com a qual estamos trabalhando. 

\begin{table}
\begin{center}
\begin{tabular}[c]{| c | c | c |}
    \hline
    \textbf{Base de Dados} & \textbf{Distribuição dos Atributos} \\
    \hline
    Alunos Jovens da FT & Gaussiana \\
    \hline
    Alunos Jovens da Licenciatura & Bernoulli \\
    \hline
    Alunos Jovens da Computação & Multinomial \\
    \hline
    Alunos Seniores & Gaussiana \\
    \hline
\end{tabular}
\end{center}
\caption{Melhor Escolha de Parâmetros Para Naive Bayes Conforme a Base de Dados}
\label{conf_nb}
\end{table}

\section{Desempenho dos Modelos de Aprendizagem de Máquina} \label{results_ml_models}
Apresenta-se nesta seção os desempenhos dos vários modelos de aprendizagem de
máquina para, em seguida, discutir os resultados obtidos. Nas Tabelas
\ref{fmeasure_ft}, \ref{fmeasure_lic}, \ref{fmeasure_comp} e \ref{fmeasure_old} são 
mostrados os desempenhos para as bases de dados dos alunos jovens da FT, alunos
jovens da licenciatura, alunos jovens da computação e alunos seniores
respectivamente. O valor de \textit{F-measure} mostrado corresponde a média dos valores de
\textit{F-measure} obtidos semestre a semestre.  

\begin{table}
\begin{center}
\begin{tabular}[c]{| c | c |}
    \hline
    \textbf{Modelo} & \textbf{F-measure} \\
    \hline
    ANN              & 0.76 \\
    \hline
    Naive Bayes      & 0.56 \\
    \hline
    Random Forest    & 0.73 \\
    \hline
    Regressor Linear & 0.80 \\
    \hline
    SVR              & 0.76 \\
    \hline
    ZeroR            & 0.64 \\
    \hline
\end{tabular}
\end{center}
\caption{F-measure Média por Modelo, para Alunos Jovens da FT}
\label{fmeasure_ft}
\end{table}

\begin{table}
\begin{center}
\begin{tabular}[c]{| c | c |}
    \hline
    \textbf{Modelo} & \textbf{F-measure} \\
    \hline
    ANN              & 0.85 \\
    \hline
    Naive Bayes      & 0.76 \\
    \hline
    Random Forest    & 0.85 \\
    \hline
    Regressor Linear & 0.86 \\
    \hline
    SVR              & 0.82 \\
    \hline
    ZeroR            & 0.70 \\
    \hline
\end{tabular}
\end{center}
\caption{F-measure Média por Modelo, para Alunos Jovens de Licenciatura}
\label{fmeasure_lic}
\end{table}

\begin{table}
\begin{center}
\begin{tabular}[c]{| c | c |}
    \hline
    \textbf{Modelo} & \textbf{F-measure} \\
    \hline
    ANN              & 0.74 \\
    \hline
    Naive Bayes      & 0.65 \\
    \hline
    Random Forest    & 0.76 \\
    \hline
    Regressor Linear & 0.77 \\
    \hline
    SVR              & 0.70 \\
    \hline
    ZeroR            & 0.60 \\
    \hline
\end{tabular}
\end{center}
\caption{F-measure Média por Modelo, para Alunos Jovens da Computação}
\label{fmeasure_comp}
\end{table}

\begin{table}
\begin{center}
\begin{tabular}[c]{| c | c |}
    \hline
    \textbf{Modelo} & \textbf{F-measure} \\
    \hline
    ANN              & 0.62 \\
    \hline
    Naive Bayes      & 0.28 \\
    \hline
    Random Forest    & 0.70 \\
    \hline
    Regressor Linear & 0.75 \\
    \hline
    SVR              & 0.79 \\
    \hline
    ZeroR            & 0.61 \\
    \hline
\end{tabular}
\end{center}
\caption{F-measure Média por Modelo, para Alunos Seniores}
\label{fmeasure_old}
\end{table}

\par Os resultados mostram que, de forma geral, os modelos de aprendizagem de máquina
conseguem ter um resultado melhor que o ZeroR (à exceção do Naive Bayes). O melhor
desempenho dos modelos em relação ao ZeroR era esperado, já que o ZeroR é bastante
simples. Atribui-se o mau desempenho do Naive Bayes ao
fato de que os atributos passados não seguem todos uma mesma distribuição (seja ela
gaussiana, multinomial ou Bernoulli). 
\par Por fim, deve-se ressaltar o bom desempenho obtido pelo regressor linear. Tal
técnica obteve o melhor desempenho em três das quatro bases de dados (perdendo apenas
para a SVR na base de dados dos alunos seniores) e obteve um valor de
\textit{F-measure} médio em torno de 0.795. Isso está de acordo com a teoria de
aprendizagem de máquina, que afirma que modelos lineares não são propensos à
\textit{overfitting} e que são boas alternativas iniciais em geral
\cite{ml_second_book}. 
